{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Experiment to compare PyTorch, and TensorFlow on CPU runtime\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Function to measure time for PyTorch (CPU)\n",
        "def pytorch_cpu_test(matrix):\n",
        "    # Ensure strict symmetry and use float64 for precision\n",
        "    matrix = (matrix + matrix.T) / 2\n",
        "    torch_matrix = torch.tensor(matrix, dtype=torch.float64)  # Use float64 for better stability\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        eigenvalues, eigenvectors = torch.linalg.eigh(torch_matrix)  # Preferred method\n",
        "        end_time = time.time()\n",
        "    except RuntimeError:\n",
        "        print(\"Fallback to symeig due to RuntimeError.\")\n",
        "        start_time = time.time()\n",
        "        eigenvalues, eigenvectors = torch.symeig(torch_matrix, eigenvectors=True)  # Fallback\n",
        "        end_time = time.time()\n",
        "\n",
        "    return end_time - start_time, None, None  # Skip memory tracking for CPU\n",
        "\n",
        "# Function to measure time for TensorFlow (CPU)\n",
        "def tensorflow_cpu_test(matrix):\n",
        "    tf_matrix = tf.convert_to_tensor(matrix, dtype=tf.float32)  # Ensure TensorFlow uses CPU\n",
        "    start_time = time.time()\n",
        "    eigenvalues, eigenvectors = tf.linalg.eigh(tf_matrix)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time, None, None  # TensorFlow memory tracking disabled for CPU\n",
        "\n",
        "# Testing matrix sizes\n",
        "matrix_sizes = [10, 100, 500, 1000, 2500, 5000]\n",
        "results = {\"size\": [], \"pytorch\": [], \"tensorflow\": []}\n",
        "\n",
        "# Run experiments\n",
        "for size in matrix_sizes:\n",
        "    print(f\"Testing matrix size: {size}x{size}\")\n",
        "    matrix = np.random.rand(size, size)\n",
        "    matrix = (matrix + matrix.T) / 2  # Ensure symmetry\n",
        "\n",
        "    # PyTorch\n",
        "    pytorch_time, pytorch_current, pytorch_peak = pytorch_cpu_test(matrix)\n",
        "    # TensorFlow\n",
        "    tensorflow_time, tensorflow_current, tensorflow_peak = tensorflow_cpu_test(matrix)\n",
        "\n",
        "    results[\"size\"].append(size)\n",
        "    results[\"pytorch\"].append((pytorch_time, pytorch_current, pytorch_peak))\n",
        "    results[\"tensorflow\"].append((tensorflow_time, tensorflow_current, tensorflow_peak))\n",
        "\n",
        "    print(f\"Matrix size {size}x{size}:\")\n",
        "    print(f\"  PyTorch: Time={pytorch_time:.4f}s\")\n",
        "    print(f\"  TensorFlow: Time={tensorflow_time:.4f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCTR5E3pXPcs",
        "outputId": "79dfef00-9d74-4d93-9b59-5e688147db44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing matrix size: 10x10\n",
            "Matrix size 10x10:\n",
            "  PyTorch: Time=0.0043s\n",
            "  TensorFlow: Time=0.0002s\n",
            "Testing matrix size: 100x100\n",
            "Matrix size 100x100:\n",
            "  PyTorch: Time=0.0221s\n",
            "  TensorFlow: Time=0.0011s\n",
            "Testing matrix size: 500x500\n",
            "Matrix size 500x500:\n",
            "  PyTorch: Time=0.0400s\n",
            "  TensorFlow: Time=0.0514s\n",
            "Testing matrix size: 1000x1000\n",
            "Matrix size 1000x1000:\n",
            "  PyTorch: Time=0.2950s\n",
            "  TensorFlow: Time=0.4868s\n",
            "Testing matrix size: 2500x2500\n",
            "Matrix size 2500x2500:\n",
            "  PyTorch: Time=3.8300s\n",
            "  TensorFlow: Time=10.5320s\n",
            "Testing matrix size: 5000x5000\n",
            "Matrix size 5000x5000:\n",
            "  PyTorch: Time=36.1616s\n",
            "  TensorFlow: Time=103.6179s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment on (Numpy), PyTorch, and TensorFlow on GPU runtime\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Function to measure memory and time for NumPy\n",
        "def numpy_memory_test(matrix):\n",
        "    start_time = time.time()\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(matrix)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time, None, None  # NumPy does not provide memory tracking\n",
        "\n",
        "# Function to measure memory and time for PyTorch\n",
        "def pytorch_memory_test(matrix):\n",
        "    torch_matrix = torch.tensor(matrix, dtype=torch.float32, device=\"cuda\")\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    start_time = time.time()\n",
        "    eigenvalues, eigenvectors = torch.linalg.eigh(torch_matrix)\n",
        "    end_time = time.time()\n",
        "    current_memory = torch.cuda.memory_allocated()\n",
        "    peak_memory = torch.cuda.max_memory_allocated()\n",
        "    return end_time - start_time, current_memory, peak_memory\n",
        "\n",
        "# Function to measure memory and time for TensorFlow\n",
        "def tensorflow_memory_test(matrix):\n",
        "    tf_matrix = tf.convert_to_tensor(matrix, dtype=tf.float32)\n",
        "    tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
        "    start_time = time.time()\n",
        "    eigenvalues, eigenvectors = tf.linalg.eigh(tf_matrix)\n",
        "    end_time = time.time()\n",
        "    memory_info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
        "    current_memory = memory_info[\"current\"]\n",
        "    peak_memory = memory_info[\"peak\"]\n",
        "    return end_time - start_time, current_memory, peak_memory\n",
        "\n",
        "# Testing matrix sizes\n",
        "matrix_sizes = [10, 100, 500, 1000, 2500, 5000]\n",
        "results = {\"size\": [], \"numpy\": [], \"pytorch\": [], \"tensorflow\": []}\n",
        "\n",
        "# Run experiments\n",
        "for size in matrix_sizes:\n",
        "    print(f\"Testing matrix size: {size}x{size}\")\n",
        "    matrix = np.random.rand(size, size)\n",
        "    matrix = (matrix + matrix.T) / 2  # Ensure symmetry\n",
        "\n",
        "    # NumPy\n",
        "    numpy_time, numpy_current, numpy_peak = numpy_memory_test(matrix)\n",
        "    # PyTorch\n",
        "    pytorch_time, pytorch_current, pytorch_peak = pytorch_memory_test(matrix)\n",
        "    # TensorFlow\n",
        "    tensorflow_time, tensorflow_current, tensorflow_peak = tensorflow_memory_test(matrix)\n",
        "\n",
        "    results[\"size\"].append(size)\n",
        "    results[\"numpy\"].append((numpy_time, numpy_current, numpy_peak))\n",
        "    results[\"pytorch\"].append((pytorch_time, pytorch_current, pytorch_peak))\n",
        "    results[\"tensorflow\"].append((tensorflow_time, tensorflow_current, tensorflow_peak))\n",
        "\n",
        "    print(f\"Matrix size {size}x{size}:\")\n",
        "    print(f\"  NumPy: Time={numpy_time:.4f}s\")\n",
        "    print(f\"  PyTorch: Time={pytorch_time:.4f}s, Current={pytorch_current/1e6:.2f}MB, Peak={pytorch_peak/1e6:.2f}MB\")\n",
        "    print(f\"  TensorFlow: Time={tensorflow_time:.4f}s, Current={tensorflow_current/1e6:.2f}MB, Peak={tensorflow_peak/1e6:.2f}MB\")\n"
      ],
      "metadata": {
        "id": "lPXjUa_IgRMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3362e42-3134-4f92-9bd7-fb8b77d20c13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing matrix size: 10x10\n",
            "Matrix size 10x10:\n",
            "  NumPy: Time=0.0149s\n",
            "  PyTorch: Time=0.5725s, Current=0.00MB, Peak=0.14MB\n",
            "  TensorFlow: Time=0.2235s, Current=0.00MB, Peak=0.14MB\n",
            "Testing matrix size: 100x100\n",
            "Matrix size 100x100:\n",
            "  NumPy: Time=0.0222s\n",
            "  PyTorch: Time=0.0345s, Current=0.08MB, Peak=0.14MB\n",
            "  TensorFlow: Time=0.0060s, Current=0.08MB, Peak=0.47MB\n",
            "Testing matrix size: 500x500\n",
            "Matrix size 500x500:\n",
            "  NumPy: Time=0.0925s\n",
            "  PyTorch: Time=0.0699s, Current=2.00MB, Peak=3.08MB\n",
            "  TensorFlow: Time=0.1158s, Current=2.10MB, Peak=11.49MB\n",
            "Testing matrix size: 1000x1000\n",
            "Matrix size 1000x1000:\n",
            "  NumPy: Time=0.4309s\n",
            "  PyTorch: Time=0.1713s, Current=8.00MB, Peak=20.98MB\n",
            "  TensorFlow: Time=0.0452s, Current=8.20MB, Peak=29.37MB\n",
            "Testing matrix size: 2500x2500\n",
            "Matrix size 2500x2500:\n",
            "  NumPy: Time=3.7158s\n",
            "  PyTorch: Time=0.2419s, Current=50.34MB, Peak=125.84MB\n",
            "  TensorFlow: Time=0.1916s, Current=58.57MB, Peak=234.89MB\n",
            "Testing matrix size: 5000x5000\n",
            "Matrix size 5000x5000:\n",
            "  NumPy: Time=41.3265s\n",
            "  PyTorch: Time=1.0561s, Current=201.35MB, Peak=501.61MB\n",
            "  TensorFlow: Time=1.0716s, Current=234.24MB, Peak=939.55MB\n"
          ]
        }
      ]
    }
  ]
}